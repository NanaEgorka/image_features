{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tifffile as tiff\nimport matplotlib.pyplot as plt\nimport os\nfrom PIL import Image\n\nimport random\nfrom IPython.display import display, clear_output\nfrom tqdm.notebook import tqdm\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nimport os","metadata":{"execution":{"iopub.status.busy":"2023-01-16T13:38:44.815855Z","iopub.execute_input":"2023-01-16T13:38:44.816325Z","iopub.status.idle":"2023-01-16T13:38:46.380783Z","shell.execute_reply.started":"2023-01-16T13:38:44.816246Z","shell.execute_reply":"2023-01-16T13:38:46.379813Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def set_random_seed(seed):\n    torch.backends.cudnn.deterministic = True\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    \nset_random_seed(7)","metadata":{"execution":{"iopub.status.busy":"2023-01-16T13:40:51.710578Z","iopub.execute_input":"2023-01-16T13:40:51.710959Z","iopub.status.idle":"2023-01-16T13:40:51.718769Z","shell.execute_reply.started":"2023-01-16T13:40:51.710922Z","shell.execute_reply":"2023-01-16T13:40:51.717790Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class CroppedDataset(Dataset): # assume that all shapes are the same\n    def __init__(self, folder_path, patch_size=(32, 32)):\n        super().__init__()\n        self.folder_path = folder_path\n        self.image_pathes = os.listdir(folder_path)\n        self.patch_size = patch_size\n        \n        img = plt.imread(os.path.join(self.folder_path, self.image_pathes[0]))\n        img = img[:-38] ## cut the bottom line\n        self.patches_i = int(img.shape[0] / self.patch_size[0])\n        self.patches_j = int(img.shape[1] / self.patch_size[1])\n        self.n_patches = self.patches_i * self.patches_j\n        \n        self.data = []\n        self.means = []\n        self.stds = []\n        for path in self.image_pathes:\n            img = plt.imread(os.path.join(self.folder_path, path))\n            if len(img.shape) > 2:\n                img = img[:, :, 0]\n            img = img[:-38] ## cut the bottom line\n            img = img / 255\n            #img = img.round() ## binarization\n            mean, std = img.mean(), img.std()\n            #if std == 0:\n            #    std = 1\n            self.means.append(mean)\n            self.stds.append(std)\n            #img = (img - mean) / std\n            #img = img.round()\n            img = (img > mean).astype(int)\n            self.data.append(img)\n\n    def __len__(self):\n        return len(self.image_pathes) * self.n_patches\n\n    def __getitem__(self, index):\n        img_index = index // self.n_patches\n        #img = plt.imread(os.path.join(self.folder_path, self.image_pathes[img_index]))\n        img = self.data[img_index]\n        patch_index = index % self.n_patches ## select patch\n        patch_i = patch_index // self.patches_j\n        patch_j = patch_index % self.patches_j\n        img = img[patch_i * self.patch_size[0]:(patch_i + 1) * self.patch_size[0],\n                 patch_j * self.patch_size[1]:(patch_j + 1) * self.patch_size[1]]\n        return img, self.means[img_index], self.stds[img_index]","metadata":{"execution":{"iopub.status.busy":"2023-01-16T13:40:51.886639Z","iopub.execute_input":"2023-01-16T13:40:51.887207Z","iopub.status.idle":"2023-01-16T13:40:51.899562Z","shell.execute_reply.started":"2023-01-16T13:40:51.887167Z","shell.execute_reply":"2023-01-16T13:40:51.898646Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"folder_path = '/kaggle/input/vkr-data/data2/micrographs/'\n\ndataset = CroppedDataset(folder_path)","metadata":{"execution":{"iopub.status.busy":"2023-01-16T13:40:52.659374Z","iopub.execute_input":"2023-01-16T13:40:52.659707Z","iopub.status.idle":"2023-01-16T13:41:04.724390Z","shell.execute_reply.started":"2023-01-16T13:40:52.659680Z","shell.execute_reply":"2023-01-16T13:41:04.723445Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_size = int(len(dataset) * 0.8)\nval_size = len(dataset) - train_size\n\ntrain_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size],\n                                                           generator=torch.Generator().manual_seed(7))","metadata":{"execution":{"iopub.status.busy":"2023-01-16T13:41:04.726195Z","iopub.execute_input":"2023-01-16T13:41:04.726575Z","iopub.status.idle":"2023-01-16T13:41:04.755189Z","shell.execute_reply.started":"2023-01-16T13:41:04.726539Z","shell.execute_reply":"2023-01-16T13:41:04.754362Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import torchvision.transforms as T\n\ntrain_dataloader = DataLoader(train_dataset, batch_size = 512, shuffle = True, num_workers=2)\nval_dataloader = DataLoader(val_dataset, batch_size = 512, shuffle = False, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2023-01-16T13:41:04.757569Z","iopub.execute_input":"2023-01-16T13:41:04.757838Z","iopub.status.idle":"2023-01-16T13:41:04.951973Z","shell.execute_reply.started":"2023-01-16T13:41:04.757812Z","shell.execute_reply":"2023-01-16T13:41:04.951036Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class AutoEncoder(nn.Module):\n    def __init__(self, latent_dim):\n        super().__init__()\n        self.latent_dim = latent_dim\n        self.encoder = nn.Sequential(\n            nn.Conv2d(1, 8, 3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(8, 16, 3, stride=2, padding=1),\n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n            nn.Conv2d(16, 32, 3, stride=2, padding=0),\n            nn.ReLU()\n        )\n        self.flatten = nn.Flatten(start_dim=1)\n        self.linear1 = nn.Sequential(\n            nn.Linear(7 * 7 * 32, 128),\n            nn.ReLU(),\n            nn.Linear(128, self.latent_dim)\n        )\n        self.unflatten = nn.Unflatten(dim=1, unflattened_size=(32, 7, 7))\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(32, 16, 3, stride=2, output_padding=1),\n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n            nn.ConvTranspose2d(16, 8, 3, stride=2, padding=1, output_padding=1),\n            nn.BatchNorm2d(8),\n            nn.ReLU(),\n            nn.ConvTranspose2d(8, 2, 3, stride=1, padding=1)\n        )\n        self.linear2 = nn.Sequential(\n            nn.Linear(self.latent_dim, 128),\n            nn.ReLU(),\n            nn.Linear(128, 7 * 7 * 32),\n            nn.ReLU()\n        )\n        \n        \n    def forward(self, x):      \n        x = self.encoder(x)\n        x = self.flatten(x)\n        x = self.linear1(x)\n        \n        x = self.linear2(x)\n        x = self.unflatten(x)\n        x = self.decoder(x)\n        \n        return x\n        \n        ","metadata":{"execution":{"iopub.status.busy":"2023-01-16T13:41:04.954095Z","iopub.execute_input":"2023-01-16T13:41:04.954413Z","iopub.status.idle":"2023-01-16T13:41:04.966195Z","shell.execute_reply.started":"2023-01-16T13:41:04.954387Z","shell.execute_reply":"2023-01-16T13:41:04.965197Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from IPython.display import display, clear_output\nfrom ipywidgets import Output\nfrom tqdm.auto import trange\nfrom typing import Type, Union\nimport matplotlib.pyplot as plt\n\n\ndef train_epoch(\n    model: nn.Module, \n    train_dataloader: torch.utils.data.DataLoader, \n    optimizer: torch.optim.Optimizer, \n    verbose_num_iters: int = 32,\n    device: torch.device = \"cuda\", \n    conditional: bool = False\n):\n    model.to(device)\n    model.train()\n    epoch_loss_trace = []\n    \n    display()\n    out = Output()\n    display(out)\n    \n    for i, (x, mean, std) in tqdm(enumerate(train_dataloader), leave=False, total=len(train_dataloader)):\n        x = x.unsqueeze(1).float()\n        x = x.to(device)\n        reconstructed_x = model(x)\n        loss = criterion(torch.flatten(reconstructed_x, start_dim=2),\n                        torch.flatten(x, start_dim=2).squeeze(1).long())\n        reconstructed_x = torch.softmax(reconstructed_x, dim=1).argmax(dim=1).unsqueeze(1)\n        \n        #loss = criterion(x, reconstructed_x)\n        \n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        epoch_loss_trace.append(loss.item())\n\n        if (i + 1) % verbose_num_iters == 0:\n            with out:\n                clear_output(wait=True)\n\n                plt.figure(figsize=(10, 5))\n                plt.subplot(1, 2, 1)\n                plt.title(\"Current epoch loss\", fontsize=22)\n                plt.xlabel(\"Iteration\", fontsize=16)\n                plt.ylabel(\"Reconstruction loss\", fontsize=16)\n                plt.grid()\n                plt.plot(epoch_loss_trace)\n\n                for j in range(3):\n                    plt.subplot(2, 6, 4 + j)\n                    plt.axis(\"off\")\n                    plt.imshow(x[j].permute(1, 2, 0).cpu().detach().numpy(), cmap='gray')\n\n                    plt.subplot(2, 6, 10 + j)\n                    plt.axis(\"off\")\n                    plt.imshow(reconstructed_x[j].permute(1, 2, 0).cpu().detach().numpy(), cmap='gray')\n\n                plt.show()\n    \n    out.clear_output()\n    \n    return epoch_loss_trace\n\n\ndef train_model(\n    model: nn.Module, \n    train_dataloader: torch.utils.data.DataLoader, \n    optimizer: torch.optim.Optimizer, \n    num_epochs: int = 5, \n    verbose_num_iters: int = 32,\n    device: torch.device = \"cuda\",\n    conditional: bool = False\n):\n    loss_trace = []\n    for epoch in tqdm(range(num_epochs), desc=\"Epoch: \", leave=True):        \n        epoch_loss_trace = train_epoch(\n            model=model,\n            train_dataloader=train_dataloader,\n            optimizer=optimizer,\n            verbose_num_iters=verbose_num_iters,\n            device=device,\n            conditional=conditional\n        )\n        \n        loss_trace += epoch_loss_trace\n        \n    plt.figure(figsize=(10, 5))\n    plt.title(\"Total training loss\", fontsize=22)\n    plt.xlabel(\"Iteration\", fontsize=16)\n    plt.ylabel(\"Reconstruction loss\", fontsize=16)\n    plt.grid()\n    plt.plot(loss_trace)\n    plt.show()\n    \n    model.eval()","metadata":{"execution":{"iopub.status.busy":"2023-01-16T13:41:04.967784Z","iopub.execute_input":"2023-01-16T13:41:04.968537Z","iopub.status.idle":"2023-01-16T13:41:04.987153Z","shell.execute_reply.started":"2023-01-16T13:41:04.968500Z","shell.execute_reply":"2023-01-16T13:41:04.986235Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model = AutoEncoder(latent_dim=32)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ncriterion = nn.CrossEntropyLoss()\ntrain_model(model, train_dataloader, optimizer, device=device, num_epochs=20)","metadata":{"execution":{"iopub.status.busy":"2023-01-16T13:41:04.988909Z","iopub.execute_input":"2023-01-16T13:41:04.989302Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"804789abe1e0469c8f8222b4e14b415d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98eebc6b5592478baf9db455b256ea95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/451 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6d173f41e254a19a64b3e6b9a81553d"}},"metadata":{}}]},{"cell_type":"code","source":"def predict(model, loader):\n    original = []\n    reconstructed = []\n    for i, (x, mean, std) in tqdm(enumerate(loader), leave=False, total=len(loader)):\n        std = std[:, None, None, None]\n        mean = mean[:, None, None, None]\n        x = x.unsqueeze(1).float()\n        x = x.to(device)\n        reconstructed_x = model(x).cpu()\n        reconstructed_x = torch.softmax(reconstructed_x, dim=1).argmax(dim=1).unsqueeze(1)\n        original.append(x)\n        reconstructed.append(reconstructed_x)\n    return original, reconstructed","metadata":{"execution":{"iopub.status.busy":"2023-01-15T20:50:17.194362Z","iopub.execute_input":"2023-01-15T20:50:17.195242Z","iopub.status.idle":"2023-01-15T20:50:17.203190Z","shell.execute_reply.started":"2023-01-15T20:50:17.195203Z","shell.execute_reply":"2023-01-15T20:50:17.202386Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"original, reconstructed = predict(model, val_dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-01-15T20:50:17.208367Z","iopub.execute_input":"2023-01-15T20:50:17.208972Z","iopub.status.idle":"2023-01-15T20:50:31.190152Z","shell.execute_reply.started":"2023-01-15T20:50:17.208937Z","shell.execute_reply":"2023-01-15T20:50:31.189063Z"},"trusted":true},"execution_count":36,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/113 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, accuracy_score\n\nprint('Accuracy:', accuracy_score(torch.cat(original).cpu().detach().numpy().astype(int).flatten(),\n               torch.cat(reconstructed).cpu().detach().numpy().astype(int).flatten()))\n\nprint('MSE:', mean_squared_error(torch.cat(original).cpu().detach().numpy().astype(int).flatten(),\n               torch.cat(reconstructed).cpu().detach().numpy().astype(int).flatten()))","metadata":{"execution":{"iopub.status.busy":"2023-01-15T20:50:31.192406Z","iopub.execute_input":"2023-01-15T20:50:31.192848Z","iopub.status.idle":"2023-01-15T20:50:39.782733Z","shell.execute_reply.started":"2023-01-15T20:50:31.192796Z","shell.execute_reply":"2023-01-15T20:50:39.781606Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Accuracy: 0.7868782924687825\nMSE: 0.21312170753121748\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}